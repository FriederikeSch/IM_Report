{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matches premises to claims on the small essay corpus with a Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import statistics\n",
    "from sklearn.metrics import f1_score\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataframes\n",
    "ent_frame_list = pickle.load( open( \"pickles/ent_frame_list.p\", \"rb\" ) )\n",
    "att_frame_list = pickle.load( open( \"pickles/att_frame_list.p\", \"rb\" ) )\n",
    "rel_frame_list = pickle.load( open( \"pickles/rel_frame_list.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up text \n",
    "ent_frame_list[0]\n",
    "for i in ent_frame_list:\n",
    "    for j in range(len(i)):\n",
    "        i.iloc[j,0]= i.iloc[j,0].replace(\"text=\",\"\")\n",
    "        i.iloc[j,0]= i.iloc[j,0].replace(')','')\n",
    "        i.iloc[j,0]= i.iloc[j,0].replace('\\'','')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Targets</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we should attach more importance to cooperati...</td>\n",
       "      <td>T1</td>\n",
       "      <td>MajorClaim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"a more cooperative attitudes towards life is...</td>\n",
       "      <td>T2</td>\n",
       "      <td>MajorClaim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>through cooperation, children can learn about...</td>\n",
       "      <td>T3</td>\n",
       "      <td>Claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What we acquired from team work is not only h...</td>\n",
       "      <td>T4</td>\n",
       "      <td>Claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>During the process of cooperation, children c...</td>\n",
       "      <td>T5</td>\n",
       "      <td>Premise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>All of these skills help them to get on well ...</td>\n",
       "      <td>T6</td>\n",
       "      <td>Premise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>competition makes the society more effective</td>\n",
       "      <td>T7</td>\n",
       "      <td>Claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the significance of competition is that how t...</td>\n",
       "      <td>T8</td>\n",
       "      <td>Premise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>when we consider about the question that how ...</td>\n",
       "      <td>T9</td>\n",
       "      <td>Claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Take Olympic games which is a form of competi...</td>\n",
       "      <td>T10</td>\n",
       "      <td>Premise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>without the cooperation, there would be no vi...</td>\n",
       "      <td>T11</td>\n",
       "      <td>Claim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text Targets        Type\n",
       "0    we should attach more importance to cooperati...      T1  MajorClaim\n",
       "1    \"a more cooperative attitudes towards life is...      T2  MajorClaim\n",
       "2    through cooperation, children can learn about...      T3       Claim\n",
       "3    What we acquired from team work is not only h...      T4       Claim\n",
       "4    During the process of cooperation, children c...      T5     Premise\n",
       "5    All of these skills help them to get on well ...      T6     Premise\n",
       "6        competition makes the society more effective      T7       Claim\n",
       "7    the significance of competition is that how t...      T8     Premise\n",
       "8    when we consider about the question that how ...      T9       Claim\n",
       "9    Take Olympic games which is a form of competi...     T10     Premise\n",
       "10   without the cooperation, there would be no vi...     T11       Claim"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_frame_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from gensim.parsing.preprocessing import remove_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a word2vec model for each text\n",
    "model_list=[]\n",
    "for i in ent_frame_list:\n",
    "    \n",
    "    examp=i\n",
    "    \n",
    "    text_list = examp['text'].tolist()\n",
    "\n",
    "    word_list=[]\n",
    "    for sent in text_list:\n",
    "\n",
    "\n",
    "        hold=sent_tokenize(sent)\n",
    "        \n",
    "        for word in hold:\n",
    "\n",
    "            filtered_sentence = remove_stopwords(word)\n",
    "           \n",
    "            word_list.append(word_tokenize(filtered_sentence))\n",
    "\n",
    "\n",
    "    model = gensim.models.Word2Vec(word_list, min_count = 1,\n",
    "    vector_size = 50, window = 20,sg=1, compute_loss=True)\n",
    "    \n",
    "    \n",
    "    model.train(word_list, total_examples=model.corpus_count, epochs = 30, compute_loss=True)\n",
    "    \n",
    "    model_list.append(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('members', 0.8606662154197693),\n",
       " ('occurred', 0.8433937430381775),\n",
       " ('Olympic', 0.8353438973426819),\n",
       " (',', 0.8351609110832214),\n",
       " ('gain', 0.8208107352256775),\n",
       " ('games', 0.8199472427368164),\n",
       " ('diet', 0.8074123859405518),\n",
       " ('care', 0.8023310899734497),\n",
       " ('compromise', 0.7992647886276245),\n",
       " ('win', 0.7862445116043091)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=model_list[0]\n",
    "\n",
    "len(model.wv)\n",
    "model.wv.most_similar(\"cooperation\",topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note about the support relationship types: The data allows for the following support realtionships: premise-claim, claim-claim, premise-premise and claim-premise. In cases where the relation is not premise-claim another claim will be supported upwards in this chain. To solve this in our data we ignored the indirect support relationship and focused on the direct support relation present in the data. Therefore we ignored the types of the Targets in the realtion and assigned every relation to describe a premise-claim support relation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a list of dataframes containing every relation in the frame and the text belonging to the targets\n",
    "frame_list=[]\n",
    "\n",
    "for i in range(len(ent_frame_list)):\n",
    "\n",
    "    \n",
    "    p=pd.merge(att_frame_list[i],ent_frame_list[i],on=\"Targets\")\n",
    "    \n",
    "    p=p.loc[p[\"Type_x\"]==\"PremiseType\"]\n",
    "\n",
    "    text_list = p['text'].tolist()\n",
    "\n",
    "    d=att_frame_list[i]\n",
    "    d=d.loc[d[\"Type\"]==\"ClaimType\"]\n",
    "\n",
    "\n",
    "    g=pd.merge(rel_frame_list[i],ent_frame_list[i],on=\"Targets\")\n",
    "    g=pd.merge(g,ent_frame_list[i],left_on=\"Supported\",right_on=\"Targets\")\n",
    "    g=pd.merge(g,d,left_on=\"Supported\",right_on=\"Targets\",how=\"left\")\n",
    "\n",
    "\n",
    "    g=g.drop([\"ID_x\",\"Targets_y\",\"Targets\",\"Type\",\"ID_y\"],axis=1)\n",
    "    g=g.rename(columns={\"text_x\":\"Text_Targets\",\"text_y\":\"Text_Supported\",\"Targets_x\":\"Targets\",\"Type_x\":\"Type_Target\",\"Type_y\":\"Type_Supported\"})\n",
    "\n",
    "    #every support relationship is labeled as premise and claim (see cell above)\n",
    "  \n",
    "    g.loc[g.Type_Target == \"Claim\" , ['Type_Target']] = 'Premise'\n",
    "    g.loc[g.Type_Supported == \"Claim\" , ['Type_Target']] = 'Premise'\n",
    "    g.loc[g.Type_Target == \"Premise\" , ['Type_Supported']] = 'Claim'\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    frame_list.append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Targets_x</th>\n",
       "      <th>Supported</th>\n",
       "      <th>text_x</th>\n",
       "      <th>text_y</th>\n",
       "      <th>Targets_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type_x</th>\n",
       "      <th>Type_y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Claim</th>\n",
       "      <th>Claim</th>\n",
       "      <td>183</td>\n",
       "      <td>183</td>\n",
       "      <td>183</td>\n",
       "      <td>183</td>\n",
       "      <td>183</td>\n",
       "      <td>183</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Premise</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Premise</th>\n",
       "      <th>Claim</th>\n",
       "      <td>602</td>\n",
       "      <td>602</td>\n",
       "      <td>602</td>\n",
       "      <td>602</td>\n",
       "      <td>602</td>\n",
       "      <td>602</td>\n",
       "      <td>602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Premise</th>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID  Stance  Targets_x  Supported  text_x  text_y  Targets_y\n",
       "Type_x  Type_y                                                               \n",
       "Claim   Claim    183     183        183        183     183     183        183\n",
       "        Premise   16      16         16         16      16      16         16\n",
       "Premise Claim    602     602        602        602     602     602        602\n",
       "        Premise  105     105        105        105     105     105        105"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show distribution of support relationship types\n",
    "hold_list=[]\n",
    "for i in range(len(ent_frame_list)):\n",
    "    g=pd.merge(rel_frame_list[i],ent_frame_list[i],on=\"Targets\")\n",
    "    g=pd.merge(g,ent_frame_list[i],left_on=\"Supported\",right_on=\"Targets\")\n",
    "    hold_list.append(g)\n",
    "big_frame = pd.concat(hold_list)\n",
    "\n",
    "big_frame.groupby([\"Type_x\",\"Type_y\"]).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the cosine similarity between each premise and claim example\n",
    "#choose the pair with the highest value as prediction of which premise fits to which claim\n",
    "\n",
    "cos_sim_all=[]\n",
    "acc_list=[]\n",
    "\n",
    "for ex in range(len(model_list)):\n",
    "\n",
    "    #split the frame in information about the supporter(premise) and the supported(claim)\n",
    "    prem_frame= frame_list[ex][['Text_Targets', 'Targets', 'Type_Target']].copy()\n",
    "    clm_frame= frame_list[ex][['Text_Supported', 'Supported', 'Type_Supported']].copy()\n",
    "    \n",
    "    cos_sim=[]\n",
    "    #tokenize the sentences to word lists\n",
    "    for i in range(len(prem_frame)):\n",
    "        premise=word_tokenize(prem_frame.iloc[i,0])\n",
    "        \n",
    "        for j in range(len(clm_frame)):\n",
    "            #print(\"new claim\")\n",
    "            claim=word_tokenize(clm_frame.iloc[j,0])\n",
    "            \n",
    "\n",
    "            cos_sim_pair=[]\n",
    "            #for every word pair in the premise-claim pair compute the cosine similarity \n",
    "            #of the embbeded word2vec model vector\n",
    "            for word_prem in premise:\n",
    "                for word_clm in claim:\n",
    "                    try:\n",
    "                        cos_sim_pair.append(model_list[ex].wv.similarity(word_prem,word_clm))\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            cos_sim.append(statistics.mean(cos_sim_pair))\n",
    "    cos_sim_all.append(cos_sim)\n",
    "\n",
    "\n",
    "    #some texts have no premises theses are ignored \n",
    "    if len(prem_frame)==0:\n",
    "        pass\n",
    "        \n",
    "    else:\n",
    "        #split the obtained values into chunks each list shows how well all premises fits to one claim\n",
    "        #list of [p1c1, p1c2, p1c3, p2c1, p2,c2 ...]\n",
    "        length=len(prem_frame)\n",
    "        \n",
    "        id_list=[]\n",
    "        chunks = [cos_sim[x:x+length] for x in range(0, len(cos_sim), length)]\n",
    "        \n",
    "        #claims appear multiple times in the list this takes only the first highest value\n",
    "        #assumption: two different claims are never equally likely\n",
    "        for i in chunks:\n",
    "            id_list.append( max(range(len(i)), key=i.__getitem__))\n",
    "        \n",
    "        #get the claim id \n",
    "        claim_list=[]\n",
    "        for i in id_list:\n",
    "            claim_list.append(clm_frame.iloc[i,1])\n",
    "        \n",
    "        #make a list of tuple with the premise and the predicted claim\n",
    "        prem_frame[\"claim\"]=claim_list\n",
    "        pred_list=list(zip(prem_frame.claim, prem_frame.Targets))\n",
    "        #flip tuples\n",
    "        pred_list = [t[::-1] for t in pred_list]\n",
    "\n",
    "        #get a tuple list with the real premise claim pairs\n",
    "        real_list=list(zip(frame_list[ex].Targets, frame_list[ex].Supported))\n",
    "        \n",
    "        rigth_set=set(pred_list) & set(real_list)\n",
    "       \n",
    "        acc=len(rigth_set)/len(real_list)\n",
    "        acc_list.append(acc)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26609069035539623\n"
     ]
    }
   ],
   "source": [
    "print(statistics.mean(acc_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0acc6f63e5576177c66e256d998b6d3964615254c3e54055c5c863c51bc5dfdf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
