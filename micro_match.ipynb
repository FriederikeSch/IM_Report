{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a dataframe from the micro corpus to predict premise-claim-pairs with the trained BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import itertools\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_data(num):\n",
    "    corpus_list=[\"cmv-hidey\",\"usdeb\",\"essay_1\",\"micro_struc\"]\n",
    "\n",
    "    data = []\n",
    "\n",
    "    print(\"Choosen corpus is:\",corpus_list[num])\n",
    "\n",
    "\n",
    "    with open(\"Data/\"+corpus_list[num]+\".json\") as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    if num ==3:\n",
    "       \n",
    "        df=df.drop(\"discourse\",axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choosen corpus is: micro_struc\n"
     ]
    }
   ],
   "source": [
    "df=read_in_data(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dataframe containing the relations between units and the text belonging to them\n",
    "df_list=[]\n",
    "text_list=[]\n",
    "\n",
    "for num in range(len(df)):\n",
    "    text=[]\n",
    "\n",
    "    for part_list in df.iloc[num,3]:\n",
    "        tokens=part_list[\"tokens\"]\n",
    "    \n",
    "        for word in tokens:\n",
    "            text.append(word[\"surface\"])\n",
    "\n",
    "    units=df.iloc[num,4][\"units\"]\n",
    "    arguments=df.iloc[num,4][\"arguments\"]\n",
    "\n",
    "    #look up the text id and the role of each unit\n",
    "    #the text id is given as the first and last word position of the unit\n",
    "    unit_id_list=[]\n",
    "    role_list=[]\n",
    "\n",
    "    for i in units:\n",
    "\n",
    "        unit_id=(i[\"tokens\"][0],i[\"tokens\"][-1])\n",
    "\n",
    "        unit_id_list.append(unit_id)\n",
    "        role_list.append(i[\"attributes\"][\"role\"])\n",
    "\n",
    "\n",
    "    units_dict={}\n",
    "    for i in range (0,len(units)):\n",
    "\n",
    "        units_dict[i]=unit_id_list[i],role_list[i]\n",
    "\n",
    "    #make a dataframe\n",
    "    unitframe = pd.DataFrame(arguments)\n",
    "\n",
    "    unitframe[\"unit1_role\"] = \"\"\n",
    "    unitframe[\"unit2_role\"] = \"\"\n",
    "\n",
    "    unitframe[\"unit1_id\"] = \"\"\n",
    "    unitframe[\"unit2_id\"] = \"\"\n",
    "\n",
    "    for i in range(len(unitframe)) :\n",
    "        \n",
    "\n",
    "        #add into column unit_role1/2 the role of this unit the role is taken from the units dictonary\n",
    "        #the correct entry in the dict is looked up from the unit column in the dataframe\n",
    "\n",
    "        unitframe.at[i,\"unit1_role\"]=units_dict[unitframe.at[i,\"unit1\"]][1]\n",
    "\n",
    "        unitframe.at[i,\"unit2_role\"]=units_dict[unitframe.at[i,\"unit2\"] ][1]\n",
    "\n",
    "        #the same is done with the unit id\n",
    "\n",
    "        unitframe.at[i,\"unit1_id\"]=units_dict[unitframe.at[i,\"unit1\"]][0]\n",
    "\n",
    "        unitframe.at[i,\"unit2_id\"]=units_dict[unitframe.at[i,\"unit2\"] ][0]\n",
    "     \n",
    "    df_list.append(unitframe) \n",
    "    text_list.append(text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit1</th>\n",
       "      <th>unit2</th>\n",
       "      <th>rtype</th>\n",
       "      <th>unit1_role</th>\n",
       "      <th>unit2_role</th>\n",
       "      <th>unit1_id</th>\n",
       "      <th>unit2_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>supports</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>(45, 61)</td>\n",
       "      <td>(28, 37)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>rebuts</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Claim</td>\n",
       "      <td>(28, 37)</td>\n",
       "      <td>(0, 19)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>supports</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Claim</td>\n",
       "      <td>(20, 27)</td>\n",
       "      <td>(0, 19)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>supports</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>(38, 44)</td>\n",
       "      <td>(28, 37)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit1  unit2     rtype unit1_role unit2_role  unit1_id  unit2_id\n",
       "0      4      2  supports    Premise    Premise  (45, 61)  (28, 37)\n",
       "1      2      0    rebuts    Premise      Claim  (28, 37)   (0, 19)\n",
       "2      1      0  supports    Premise      Claim  (20, 27)   (0, 19)\n",
       "3      3      2  supports    Premise    Premise  (38, 44)  (28, 37)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#match the text to the unit ids\n",
    "text_frame_list=[]\n",
    "for frame,text in zip(df_list,text_list):\n",
    "\n",
    "    unit1_text_list=[]\n",
    "    unit2_text_list=[]\n",
    "\n",
    "    for i in range(len(frame)):\n",
    "\n",
    "        #get the tuple indicating the start and end position of the text \n",
    "        # combine them into one sentence\n",
    "        pos_1=frame.iloc[i,5]\n",
    "        snip_1=text[pos_1[0]:pos_1[1]]\n",
    "        sent_1 = ' '.join(snip_1)\n",
    "    \n",
    "        pos_2=frame.iloc[i,6]\n",
    "        snip_2=text[pos_2[0]:pos_2[1]]\n",
    "        sent_2 = ' '.join(snip_2)\n",
    "        \n",
    "        unit1_text_list.append(sent_1)\n",
    "        unit2_text_list.append(sent_2)\n",
    "\n",
    "\n",
    "    frame[\"unit1_text\"]=unit1_text_list\n",
    "\n",
    "    frame[\"unit2_text\"]=unit2_text_list\n",
    "\n",
    "    text_frame_list.append(frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_big_essay(text_frame_list,even_distribution=True):\n",
    "    \"\"\"\n",
    "    The function creates a dataframe containing pairs of target texts with labels if they show actual support realtions in the essays\n",
    "    : text_frame_list: a dataframe containing the the support relations between targets and their texts\n",
    "    :even_distribution: if True the number of examples choosen is capped by the smallest class\n",
    "    \"\"\"\n",
    "    h=[]\n",
    "    \n",
    "    for i in range(len(text_frame_list)):\n",
    "        \n",
    "        #get the text from the units\n",
    "        unit_1_text = text_frame_list[i]['unit1_text'].tolist()\n",
    "        unit_2_text = text_frame_list[i]['unit2_text'].tolist()\n",
    "\n",
    "        #combine them all to get the complete text for all premises and claims\n",
    "        complete_text=unit_1_text+unit_2_text\n",
    "        complete_text = list(set(complete_text))\n",
    "\n",
    "        #holds the real support relation pairs\n",
    "        true_list=list(zip(unit_1_text,unit_2_text))\n",
    "\n",
    "        #all possible combinations of text pairs\n",
    "        all_combs=list(itertools.combinations(complete_text,2))\n",
    "        \n",
    "        #add labels to the text pairs\n",
    "        tr=(\"true\",)\n",
    "        true_labeled=[]\n",
    "        for i in true_list:\n",
    "            true_labeled.append(i+tr)\n",
    "\n",
    "\n",
    "        false_list=set(all_combs)-set(true_list)\n",
    "        fl=(\"false\",)\n",
    "        false_labeled=[]\n",
    "        for i in false_list:\n",
    "            false_labeled.append(i+fl)\n",
    "\n",
    "        #make a dataframe with the text pairs and their labels\n",
    "        labeled_list=true_labeled+false_labeled\n",
    "        random.shuffle(labeled_list)\n",
    "        labeled_list=pd.DataFrame(labeled_list)\n",
    "\n",
    "\n",
    "        labeled_list=labeled_list.rename(columns={0:\"Text_prem\",1:\"Text_sup\",2:\"Label\"})\n",
    "        labeled_list[\"text\"] = labeled_list[\"Text_prem\"] + \" \" + labeled_list[\"Text_sup\"]\n",
    "        h.append(labeled_list)\n",
    "\n",
    "\n",
    "    frame=pd.concat(h)\n",
    "\n",
    "    #for training numeric values are needed\n",
    "    frame[\"Label\"].replace(\"true\",0,inplace=True)\n",
    "    frame[\"Label\"].replace(\"false\",1,inplace=True)\n",
    "\n",
    "\n",
    "    if even_distribution==True:\n",
    "        #count examples pro class\n",
    "        val=frame[\"Label\"].value_counts()\n",
    "        \n",
    "        hold=[]\n",
    "        #for each unique value take that many examples from the dataframe and shuffle\n",
    "        for i in range(frame[\"Label\"].nunique()):\n",
    "          \n",
    "            h=frame.loc[frame[\"Label\"]==i]\n",
    "            h=h.sample(frac=1)\n",
    "            hold.append(h.iloc[0:val.min(),:])\n",
    "        frame=pd.concat(hold)\n",
    "        frame=frame.sample(frac=1)\n",
    "\n",
    "\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    464\n",
       "0    464\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame=get_frame_big_essay(text_frame_list,even_distribution=True)\n",
    "frame[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional: pickle the dataframe\n",
    "pickle.dump(frame, open( \"match_bert_frame_et_micro.p\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0acc6f63e5576177c66e256d998b6d3964615254c3e54055c5c863c51bc5dfdf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
