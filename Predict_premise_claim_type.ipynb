{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predicts the claim_type to a given premise from the trained BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextClassificationPipeline\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import BertTokenizer\n",
    "import pickle\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_type_frame = pickle.load( open( \"pickles/claim_type_frame_bt_et.p\", \"rb\" ) )\n",
    "att_frame_list = pickle.load( open( \"pickles/att_frame_list.p\", \"rb\" ) )\n",
    "ent_frame_list = pickle.load( open( \"pickles/ent_frame_list.p\", \"rb\" ) )\n",
    "rel_frame_list = pickle.load( open( \"pickles/rel_frame_list.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    " #load model\n",
    "\n",
    "possible_labels = claim_type_frame.Values.unique()\n",
    "\n",
    "label_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index\n",
    "\n",
    " model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(label_dict),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load('Modelle/finetuned_BERT_epoch_3_frame_3_b8.model', map_location=torch.device('cpu')))\n",
    "\n",
    "\n",
    "#load tokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
    "                                          do_lower_case=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_list=[]\n",
    "#class predictor\n",
    "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, top_k=None)\n",
    "\n",
    "#for i in range(1,5):\n",
    "for i in range(len(ent_frame_list)):\n",
    "    \n",
    "    #make a frame containing only premises\n",
    "    p=pd.merge(att_frame_list[i],ent_frame_list[i],on=\"Targets\")\n",
    "    \n",
    "    p=p.loc[p[\"Type_x\"]==\"PremiseType\"]\n",
    "\n",
    "    #get the text from all premises\n",
    "    text_list = p['text'].tolist()\n",
    "\n",
    "    label_list=[]\n",
    "    for j in text_list:\n",
    "        #predict label\n",
    "        res=pipe(j)\n",
    "\n",
    "        #make result as dictonary\n",
    "        hold = [item for sublist in res for item in sublist]\n",
    "        result = {}\n",
    "        for k in hold:\n",
    "            result.update(dict([tuple(k.values())]))\n",
    "\n",
    "        label_list.append(max(result, key=result.get))\n",
    "\n",
    "    label_list\n",
    "\n",
    "    #add label to dataframe\n",
    "    p[\"pred_label\"]=label_list\n",
    "\n",
    "\n",
    "    #make frame to get the true values by adding realtions from rel list\n",
    "    d=att_frame_list[i]\n",
    "    d=d.loc[d[\"Type\"]==\"ClaimType\"]\n",
    "\n",
    "\n",
    "    g=pd.merge(rel_frame_list[i],ent_frame_list[i],on=\"Targets\")\n",
    "    g=pd.merge(g,ent_frame_list[i],left_on=\"Supported\",right_on=\"Targets\")\n",
    "    g=pd.merge(g,d,left_on=\"Supported\",right_on=\"Targets\",how=\"left\")\n",
    "\n",
    "\n",
    "    g=g.drop([\"text_x\",\"text_y\",\"Targets_y\",\"Targets\",\"Type\",\"ID_y\"],axis=1)\n",
    "    g=g.rename(columns={\"Targets_x\":\"Targets\",\"Type_x\":\"Type_Target\",\"Type_y\":\"Type_Supported\"})\n",
    "\n",
    "    #prediction is onyl over premise types drop all claim support claim relations\n",
    "    g = g.drop(g[(g[\"Type_Target\"] ==\"Claim\") & (g[\"Type_Supported\"]==\"Claim\")].index)\n",
    "\n",
    "    \n",
    "    #combine predicted and true labels\n",
    "    t=pd.merge(g,p,left_on=\"Targets\",right_on=\"Targets\")\n",
    "    t=t.rename(columns={\"Values_x\":\"True_Values\"})\n",
    "    t=t.drop([\"ID_x\",\"ID\",\"Type_x\",\"text\",\"Type_y\",\"Values_y\"],axis=1)\n",
    "    \n",
    "    t[\"pred_label\"].replace(\"LABEL_0\",\"Value\",inplace=True)\n",
    "    t[\"pred_label\"].replace(\"LABEL_1\",\"Fact\",inplace=True)\n",
    "    t[\"pred_label\"].replace(\"LABEL_2\",\"Policy\",inplace=True)\n",
    "    \n",
    "    frame_list.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stance</th>\n",
       "      <th>Targets</th>\n",
       "      <th>Supported</th>\n",
       "      <th>Type_Target</th>\n",
       "      <th>Type_Supported</th>\n",
       "      <th>True_Values</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>supports</td>\n",
       "      <td>T5</td>\n",
       "      <td>T3</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Value</td>\n",
       "      <td>Fact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>supports</td>\n",
       "      <td>T6</td>\n",
       "      <td>T3</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Value</td>\n",
       "      <td>Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>supports</td>\n",
       "      <td>T10</td>\n",
       "      <td>T11</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Fact</td>\n",
       "      <td>Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>supports</td>\n",
       "      <td>T8</td>\n",
       "      <td>T7</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Fact</td>\n",
       "      <td>Fact</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Stance Targets Supported Type_Target Type_Supported True_Values  \\\n",
       "0  supports      T5        T3     Premise          Claim       Value   \n",
       "1  supports      T6        T3     Premise          Claim       Value   \n",
       "2  supports     T10       T11     Premise          Claim        Fact   \n",
       "3  supports      T8        T7     Premise          Claim        Fact   \n",
       "\n",
       "  pred_label  \n",
       "0       Fact  \n",
       "1      Value  \n",
       "2      Value  \n",
       "3       Fact  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Stance</th>\n",
       "      <th>Targets</th>\n",
       "      <th>Supported</th>\n",
       "      <th>Type_Target</th>\n",
       "      <th>Type_Supported</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True_Values</th>\n",
       "      <th>pred_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Fact</th>\n",
       "      <th>Fact</th>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Value</th>\n",
       "      <td>318</td>\n",
       "      <td>318</td>\n",
       "      <td>318</td>\n",
       "      <td>318</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Policy</th>\n",
       "      <th>Fact</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Value</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Value</th>\n",
       "      <th>Fact</th>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Value</th>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Stance  Targets  Supported  Type_Target  \\\n",
       "True_Values pred_label                                            \n",
       "Fact        Fact           119      119        119          119   \n",
       "            Value          318      318        318          318   \n",
       "Policy      Fact            26       26         26           26   \n",
       "            Value           20       20         20           20   \n",
       "Value       Fact            53       53         53           53   \n",
       "            Value           66       66         66           66   \n",
       "\n",
       "                        Type_Supported  \n",
       "True_Values pred_label                  \n",
       "Fact        Fact                   119  \n",
       "            Value                  318  \n",
       "Policy      Fact                    26  \n",
       "            Value                   20  \n",
       "Value       Fact                    53  \n",
       "            Value                   66  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_frame = pd.concat(frame_list)\n",
    "big_frame\n",
    "big_frame.groupby([\"True_Values\",\"pred_label\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fact      437\n",
       "Value     119\n",
       "Policy     46\n",
       "Name: True_Values, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_frame[\"True_Values\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value    485\n",
       "Fact     222\n",
       "Name: pred_label, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_frame[\"pred_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.26166902404526166\n",
      "f1 0.144924077219146\n"
     ]
    }
   ],
   "source": [
    "y_gold= big_frame['True_Values'].tolist()\n",
    "y_pred=big_frame[\"pred_label\"].tolist()\n",
    "\n",
    "print(\"acc\",accuracy_score(y_gold,y_pred))\n",
    "\n",
    "print(\"f1\",f1_score(y_gold,y_pred,average=\"macro\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0acc6f63e5576177c66e256d998b6d3964615254c3e54055c5c863c51bc5dfdf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
